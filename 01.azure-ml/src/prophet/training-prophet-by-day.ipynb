{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1611236671771
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "from fbprophet.plot import plot_plotly\n",
    "import plotly.offline as py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1611236671957
    }
   },
   "outputs": [],
   "source": [
    "def parse_date(v):\n",
    "    try:\n",
    "        return datetime.strptime(v, \"%Y-%m-%d %H:%m:%S\")\n",
    "    except:\n",
    "        # apply whatever remedies you deem appropriate\n",
    "        pass\n",
    "    return v\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.rename(columns={'Date':'ds', 'Count':'y'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "#datastore = ws.get_default_datastore()\n",
    "#datastore.download(\"../Data/\", prefix=\"CSV/\")\n",
    "path_to_data = \"../Data/CSV/extraction.csv\"\n",
    "\n",
    "raw_data = pd.read_csv(path_to_data, date_parser=lambda x: parse_date(x), parse_dates=[\n",
    "                 'DateOut', 'DateIn'], encoding=\"UTF-16 LE\", sep=';', quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "print(\"Read data\", len(raw_data))\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info(show_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Total observations **14.140.090**\n",
    "\n",
    "The following features report missing values: DateIn, GroCode, FuelType, BodyType, VehicType, KW, CO2Emission, fTransmis, DoorsNum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the code occurrencies-byday.py to count the number of vehicles per day and save as csv file named \"occs_all.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1611237362378
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/occurrencies/aggregated/occs_all.csv\", date_parser=lambda x: parse_date(x), parse_dates=['Date'],\n",
    "                 encoding=\"UTF-8\", sep=',', quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "# rename Date and Count columns into ds and y as Prophet requires\n",
    "df.rename(columns={'Date':'ds', 'Count':'y'}, inplace=True)\n",
    "df.drop(labels=\"Unnamed: 0\", axis=1, inplace=True)\n",
    "print(\"Data Inizio\", df.ds.min())\n",
    "print(\"Data Fine\", df.ds.max())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1611237370922
    }
   },
   "outputs": [],
   "source": [
    "print(df.describe())\n",
    "y = df.y\n",
    "x = df.ds\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Date')  \n",
    "plt.ylabel('Count')  \n",
    "\n",
    "# displaying the title \n",
    "plt.title(\"Car by Day\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Interquartile Range (IQR): IQR, il concetto utilizzato per costruire boxplot, può essere utilizzato anche per identificare i valori anomali. L'IQR è uguale alla differenza tra il 3 ° quartile (75° percentile) e il 1 ° quartile (25° percentile). È quindi possibile identificare se un punto è un valore anomalo se è inferiore a Q1–1.5 * IRQ o maggiore di Q3 + 1.5 * IQR. Ciò equivale a circa 2,698 deviazioni standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the IQ range for the outliers (out of the range ]Q1–1.5 * IRQ , Q3 + 1.5 * IQR[ )\n",
    "Q1 = int(np.percentile(df.y, 25))\n",
    "Q3 = int(np.percentile(df.y, 75))\n",
    "IRQ = Q3 - Q1\n",
    "lim_inf = Q1 - (1.5 * IRQ)\n",
    "lim_sup = Q3 + (1.5 * IRQ)\n",
    "print('\\nInterquartile Range (IQR): ', IRQ, '\\nlimite inferiore', lim_inf,'\\nlimite superiore', lim_sup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.y\n",
    "x = df.ds\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(x, y)\n",
    "# plt.axhline(y=lim_inf, color = 'red')\n",
    "plt.axhline(y=lim_sup, color = 'red')\n",
    "plt.xlabel('Count')  \n",
    "plt.ylabel('Date')  \n",
    "plt.title(\"Car by Day\",fontweight =\"bold\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.y, bins = 100)\n",
    "plt.axvline(x= lim_sup, color = 'red')\n",
    "plt.axvline(x= Q1, color = 'orange')\n",
    "plt.axvline(x= Q3, color = 'orange')\n",
    "plt.axvline(x= int(np.percentile(df.y, 50)), color = 'yellow')\n",
    "plt.xlabel('Cars') \n",
    "plt.ylabel('Frequency') \n",
    "plt.title('Car frequency distribution', \n",
    "          fontweight =\"bold\") \n",
    "plt.show()\n",
    "\n",
    "df.boxplot(column='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace outliers with None\n",
    "df.loc[(df.y < lim_inf) | (df.y > lim_sup), 'y'] = None\n",
    "print(df.y.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate a new Prophet object, then call its fit method and pass in the historical dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prophet()\n",
    "model_fit = model.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe that extends into the future a specified number of days (in our case months).\n",
    "By default it will also include the dates from the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = model.make_future_dataframe(periods=12, freq=\"M\")\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the predict method to assign to each row in future a predicted value which it names yhat, and uncertainty intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step may take some time!\n",
    "forecast = model.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = model.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # This code returns an interactive plotly Figure\n",
    "from fbprophet.plot import plot_plotly\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "fig = plot_plotly(model, forecast) \n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the components of the time series: trend, weekly seasonality, and yearly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = model.plot_components(forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.diagnostics import cross_validation\n",
    "df_cv = cross_validation(model_fit, initial='3650 days', period='180 days', horizon = '180 days')\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.diagnostics import performance_metrics\n",
    "df_p = performance_metrics(df_cv)\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE (Mean Absolute Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric='rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPE (Mean Abolute Percentage Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "fig = plot_cross_validation_metric(df_cv, metric='mape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "param_grid = {  \n",
    "    'seasonality_mode' : ['additive','multiplicative']\n",
    "    ,'changepoint_range' : [0.8, 0.95]\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "print('Parameters combination sets:', all_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**seasonality_mode**: Options are ['additive', 'multiplicative']. Default is 'additive', but many business time series will have multiplicative seasonality. This is best identified just from looking at the time series and seeing if the magnitude of seasonal fluctuations grows with the magnitude of the time series\n",
    "\n",
    "**changepoint_range**: This is the proportion of the history in which the trend is allowed to change. This defaults to 0.8, 80% of the history, meaning the model will not fit any trend changes in the last 20% of the time series. This parameter is probably better not tuned, except perhaps over a large number of time series. In that setting, [0.8, 0.95] may be a reasonable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_metrics = {\n",
    "        \"initial\" : '3650 days' \n",
    "        ,\"period\" : '180 days'\n",
    "        ,\"horizon\" : '30 days'\n",
    "    }\n",
    "\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "mapes = [] # Store the MAPEs for each params here\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(df)  # Fit model with given params\n",
    "    hp_df_cv = cross_validation(m, **args_metrics)\n",
    "    hp_df_p = performance_metrics(hp_df_cv, rolling_window=1)\n",
    "    rmses.append(hp_df_p['rmse'].values[0])\n",
    "    mapes.append(hp_df_p['mape'].values[0])\n",
    "    \n",
    "\n",
    "# Find the best parameters set\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "tuning_results['mape'] = mapes\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = all_params[np.argmin(mapes)]\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Prophet(**best_params)\n",
    "new_model_fit = new_model.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = new_model.make_future_dataframe(periods=12, freq=\"M\")\n",
    "forecast = new_model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_cv = cross_validation(new_model_fit, initial='3650 days', period='180 days', horizon = '180 days')\n",
    "new_df_p = performance_metrics(new_df_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_p[\"horizon\"].values\n",
    "y1 = df_p[\"mape\"]\n",
    "y2 = new_df_p[\"mape\"]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.plot(x.astype('timedelta64[D]') / np.timedelta64(1, 'D'), y1, \n",
    "         color='red',   \n",
    "         linewidth=1.0,  \n",
    "         linestyle='--' \n",
    "        )\n",
    "plt.plot(x.astype('timedelta64[D]') / np.timedelta64(1, 'D'), y2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}