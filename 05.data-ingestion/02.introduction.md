# Introduction  <!-- omit in TOC -->

## Contents <!-- omit in TOC -->

- [Data ingestion and analytics](#data-ingestion-and-analytics)
  - [Traditional Architecture](#traditional-architecture)
  - [Modern variations](#modern-variations)
- [Other useful aspects](#other-useful-aspects)
- [Agenda](#agenda)

## Data ingestion and analytics

Tools to integrate data from different sources and prepare them for further elaboration. Some examples:
- Medical data (patient records, drugs, diseases, hospital data...) 
- E-commerce sales, follow-up, inventory, reviews, social media interactions...

Tipically conceived for analysis:
- Dashboards, support for decisions
- Alerts (e-mail, chat messages, activate procedures)
- Often enriched with Machine learning analysis 

Data ingestion != operational communication between applications
*E.g: removing an object from inventory, after it is sold in an e-commerce website, is **not** a typical data ingestion process*.

This presentation covers the typical architecture of a Business Intelligence solution, from Data Ingestion to Analytical tools, with a focus on the former one.

### Traditional Architecture

A typical architecture for a traditional data ingestion process is composed of several components.

**Data Warehouse**: storage containing data retrieven from different applications, unified, simplified and adapted to the analysis need.

Divided in different *data mart*, each representing a *business process* (e.g.: sales, inventory, orders Each data mart provides:
- Facts: measures that we want to provide (e.g: number of sales, total earnings)
- Dimensions: order date, product categories, warehouse location

**ETL**: tool for retrieving data from external sources and load into a Data Warehouse
- *Extract* from external source
- *Transform* into target model (Data Warehouse model in this case)
- *Load* in target storage

ETL processes can operate in two ways:
- Batch: schedule the ETL process regularly (once in an hour, day or week). 
- Streaming: when real-time data are needed. The ETL process runs continously. 

**Analytical tool**: tool used to present data retrieved in the data ingestion process.
- Typical structure: dashboards with plots, synthesis text, diagrams
- Can provide alert tools
- Can be a ChatBot or be integrated in additional tools

Some well-known analytical tool are Tableau, PowerBI, even Excel can be considered as one.

### Modern variations

Current architecture often varies from traditional ones, taking into account modern challenges and opportunities.

**Data Lake**: simple storage tool, typically similar to a classical "File System", that collects all data from external sources in any format they are, without the need to *transform* them. 

This avoids the need to a unified model. Transformations can be done only when a particular analysis is needed. *E.g: no need to uniform currencies, until the need for a price analysis arise.*
In some cases, indeed, ETL tools are called ELT, as load is made before transformations.

*Nota bene*: 
- in some cases, Data Lake and Data Warehouse are put together in a single architecture.
In this way, if Data Warehouse model is changed or additional fields must be retrieved, data can be taken from Data Lake without the need to extract them again from the source, where they also might have been deleted.

**Machine Learning**: ML tools are more and more often used to enrich data retrieved from external tools.
We saw some of these tools on former lessons on ML and cognitive services.
Ideas:
- Analyse time series of sales to predict future sales and detect anomalies
- Use photos to detect category of a product in e-commerce
- Analyse reviews to detect positive and negative sentiments

## Other useful aspects

- Data ingestion tools are often used in the context of **IoT tools**. E.g: sensors sending temperatures, movements, photos...
- [**Spark**](https://spark.apache.org/) and other Big Data tools such as Hadoop are often used, typically when large quantities of data need to be analyzed in real-time or almost real time. They are optimized for making in-memory analysis in a cluster of machines working in parallel
- Search Engines like SolR or [**ElasticSearch**](https://www.elastic.co/) are often used as alternative or additional storage, typically when full-text search are needed (e.g: logs).

## Agenda

1. [Presentation](01.presentation.md) :clock12: **(00:00)**
2. **[Introduction](02.introduction.md)**
3. [Azure and microsoft resources](03.azure-cognitive-services.md) :clock1230: **(00:30)**
4. [Azure Synapse](04.tgbot-go.md) :clock1: **(01:00)**
5. [Q&A](08.q&a.md) :clock2: **(02:00)**