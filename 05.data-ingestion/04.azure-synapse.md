# Azure Synapse  <!-- omit in TOC -->

## Contents <!-- omit in TOC -->

- [General information](#general-information)
- [Demo](#demo)
  - [Create resources on Azure](#create-resources-on-azure)
  - [Create connection to external Database and a Serverless SQL Pool](#create-connection-to-external-database-and-a-serverless-sql-pool)
  - [Create a Power BI workspace and connect Synapse to it](#create-a-power-bi-workspace-and-connect-synapse-to-it)
  - [Create ETL Pipelines to import data](#create-etl-pipelines-to-import-data)
  - [Add trigger for the pipeline](#add-trigger-for-the-pipeline)
  - [Generate PowerBI Dashboards](#generate-powerbi-dashboards)
- [Agenda](#agenda)

## General information

Synapse Studio is an integrated Azure tool that allows managing all the steps of an Analytics pipeline, within a single interface.
In particular:
- It integrates a tool for designing ETL pipelines, [very similar to Azure Data Factory](https://docs.microsoft.com/en-us/azure/synapse-analytics/data-integration/concepts-data-factory-differences), with a graphical interface to create pipelines
- It allows from its interface to query and navigate the data in an Azure Data Lake Storage
- It is possible to create:
  - a dedicated Relational Database (Dedicated SQL Pool)
  - a Serverless SQL Pool, i.e. an SQL Engine containing only views (or External Tables) on the Data Lake
- It allows from its interface to connect data to a PowerBI instance and see a preview of the Dashboards
- It is possible to activate a Spark Engine with Synapse, and define Spark transformations using Jupyer Notebooks.

All the configuration and objects created within Synapse can be versioned with a Git repository.

## Demo

### Create resources on Azure

1. Create a resource group for your project
2. Open resource group, select Add --> MarketPlace --> Azure Synapse Analytics (**not private hubs**) --> Create
3. On the current screen, click on account name --> create new and select a name, same for file system name

![image.png](.attachments/image-6628b743-c705-412b-ad3c-c82bb07a3baf.png)

4. Add the remaining configuration for Synapse workspace as in the screenshot

![image.png](.attachments/image-7f1a2305-9144-4750-bde7-a90bee0ea2a7.png)

5. Click on review and create, then on Create

![image.png](.attachments/image-02a7d072-4ec7-41a5-b157-aff1efd9d344.png)
 
### Create connection to external Database and a Serverless SQL Pool

1. Open the resource group of the project
2. Open Synapse Workspace
3. Click on *Open Synapse Studio*
![image](.attachments/image-41c8fa52-7cca-4e31-a1ec-8d5b1a2a920b.png)

NB: Synapse allows you to version all the configurations in a GIT Repository. We won't go into details here, but you can switch between "Synapse Live" (no versioning) to a versioning in GIT in the upper left corner of the screen.

![image.png](.attachments/image-8374af9d-2888-46be-9851-fd6901f677bc.png)


4. Click on Manage --> Linked Services --> New

![image.png](.attachments/image-b8e2e101-7d39-42ef-81d4-0d76f4b142a7.png)

5. Select *Azure SQL Database* and click on continue
6. Provide the required information.  

![image.png](.attachments/image-83a42e49-b5aa-4e61-977e-d254f373f9be.png)

7. Click on test connection on the bottom of the page to make sure connection is successful, then click on create.

8. Click on the "Data" icon on the left, then on the "+" and SQL Database.

![image.png](.attachments/image-1b847d23-dc1f-4415-b68c-d4b6e46f7bb7.png)

9. Select "Serverless" and provide a name

![image.png](.attachments/image-90e0f90d-9fcc-40f4-8de3-34823cee78e0.png)

### Create a Power BI workspace and connect Synapse to it

1. Open [powerbi.com](https://app.powerbi.com/home)
2. Login with your own company account 
3. Click on workspaces --> Create a Workspace

![image.png](.attachments/image-d8e9aa79-10bf-46d9-8bbc-dd31357caaa2.png)

4. Provide name and description and click on save

5. Go back to Synapse, click on Manage --> Linked services --> New

![image.png](.attachments/image-b8e2e101-7d39-42ef-81d4-0d76f4b142a7.png)

6. Select Connect to Power BI or search for Power BI
7. Provide a name for the linked service and the workspace name you have just created in Power BI, then click on Create

![image.png](.attachments/image-06571588-d7e8-48b6-bf55-fcf376156497.png)

8. Click on Publish All to validate all modifications 

![image.png](.attachments/image-dc041ab9-7a53-416d-ac6f-75c56751db37.png)

### Create ETL Pipelines to import data

**The subsequent step must be executed for each business process you want to analyze, with facts and dimensions**

1. Click on the Storage sign on the left ("Data"), then on the linked tab and on the primary data lake object as in the figure. Then, click on "New folder" to create a new folder with the name of your business process.

![image.png](.attachments/image-2f5a22b0-792f-4e1c-8283-eff4e962162d.png)

2. Click on "integrate" button on the left 
![image.png](.attachments/image-16b52361-4ed8-4136-be99-99f8266e811c.png)

3. Click on the plus "+" button on the right of "integrate", then select "Pipeline"

![image.png](.attachments/image-bad2906b-5117-4607-ae38-e40a418b6655.png)

4. Provide a name for the pipeline

**The subsequent step must be repeated for each table you want to create in the Data Lake**

5. On the left bar, expand "Move and Transform" and select "Copy data" tool
 ![image.png](.attachments/image-3f818916-d992-45a9-812d-526ae18648bb.png)

6. Provide a name for the step, like copy_[table_name]
7. Click on the source tab and apply the following steps: 
   * click on "+ New" button on the right of "Source Dataset"
   * Choose Azure SQL Database as input (or your source DB)
   *  Fulfill the properties form with a name and the linked service we created for the external database, select the table (or "None" if you want to import via a query and not the full table), then click on OK.

![image.png](.attachments/image-d72585ce-393b-49f3-888c-8a5d00edd665.png)

   * The source dataset you just create should appear on the dropdown list, otherwise select it. Fulfill the rest of the source with the query (or table) of your choice.

![image.png](.attachments/image-8dfe0cba-db0a-4f2c-a219-0187dd713cae.png)

8. Go the the sink tab, click on "+ New" on the right of "Sink dataset" 
9. Select "Azure Data lake storage Gen2", then "Parquet"
10. In the subsequent form, provide a name and select the workspace default storage as linked service. 

![image.png](.attachments/image-85c9426e-6d69-4de5-9c57-5d98f01fe23c.png)

11. Click on the folder on the right of the "file path" section, then select the path in the data lake where you want to drop your data (double click on a folder to open it). You may choose the folder you created for the business process in previous steps.
12. If you wrote a query in the source section, also add the file name on the last text form of "File path" section, with ".parquet" as an extension. If you selected a table, leave it blank.

13. Click on the "Debug" button above to test the pipeline. **(NB: this will trigger the import and impute costs)** and verify if the pipeline runs successfully, in the output tab below

![image.png](.attachments/image-ea49d3c0-4a7b-4e27-aabe-52f8dbddc8d2.png)

![image.png](.attachments/image-ed9456b7-d684-4ac5-a427-15ae887e81b5.png)

14. If the pipeline terminates correctly, verify if data retrieved are correct. Click on "Data" on the left, then on "Linked" tab, click on the primary data lake as in the image below. Then, navigate to the path you selected on the steps below

![image.png](.attachments/image-857a649b-974f-42b7-9684-cfc464ccf845.png)

*Now we will create a view on the Data Lake*. 
*You may want to create external tables instead of of views. In this case, in next step select "Create an External Table" instead of SELECT TOP rows. Here an [analysis of the differences](https://www.jamesserra.com/archive/2020/11/external-tables-vs-t-sql-views-on-files-in-a-data-lake).*
![image.png](.attachments/image-6f54edea-4b53-4465-9895-ad089d34d874.png)

15. Right click on the file you created, and select "New SQL Script" --> Select TOP 100 Rows

16. Click on Run and verify if results are expected. 

![image.png](.attachments/image-9ec694a3-dee6-4513-a694-fe691cfd5ec5.png)
![image.png](.attachments/image-c65f3fae-bdaa-40ee-abd4-a8851dae9131.png)

17. Now, modify the script removing the TOP 100 text and adding at the beginning "CREATE VIEW [name] AS", as in the figure below. Also, select the database you created in the [Preliminary steps](#preliminary-steps-and-creation-of-*logical-dwh*) at the right of *use database*, then click on "Run"

18. You may want to provide a name to the Script for creating the view (on the right bar), while this is not strictly necessary

![image.png](.attachments/image-0a1c7be0-85b9-4f46-a916-9c05b0d7b959.png)

19. Click on "Validate all" tab above, and if the systems shows no errors, then click on "Commit All"

![image.png](.attachments/image-3c9d5d16-fb2e-4a0c-b164-e024bcbd7b1e.png)

### Add trigger for the pipeline

You should now define triggers to schedule the activation of the pipeline. 

1. On the created pipeline, click on Add Trigger --> "New/Edit"

![image.png](.attachments/image-1e3b86f4-ce81-497f-8f1c-59ff5989f906.png)

2. On the dropdown list, click on "New" *TODO: I think that if you already created a trigger for another pipeline, you can reuse it and avoid creating a new one. To verify.*
3. Create a new trigger providing all requested information. You may select "No" on activated to suspend the trigger and activate it later.

![image.png](.attachments/image-8f6a561d-d06e-4e5e-95ce-ee1375ae0e42.png)

### Generate PowerBI Dashboards

1. Click on the paper icon on the left (develop), then click on Power BI datasets as in the figure, then click on New Power BI datasets

![image.png](.attachments/image-16661784-1e8a-4eb7-82fa-97c406ba7cd0.png)

2. Download the PowerBI file, double click on it to open PowerBI

![image.png](.attachments/image-fd361528-ef20-4c09-8e32-7ac955fbe828.png)

3. From PowerBI, connect with your Microsoft account

![image.png](.attachments/image-6e94bc18-6c4c-42a5-b177-17eef6e8bf88.png)

4. Select the views you created in the [Import data from external source](/PROGE-Advanced-Analytics-%2D-Wiki/Import-data-from-external-source) step and click on Load

![image.png](.attachments/image-5d62856c-4ba9-494f-b398-da0609a6813c.png)

5. Select Direct Query or Import and validate
6. Verify the relationships in the correspondent view ![image.png](.attachments/image-e2e27662-1ce1-40f3-a1ea-71acf06defb1.png)
7. Prepare your analysis
8. When you finish, click on file --> publish and select the Workspace of Power BI created on previous step
9. You can now see the report in Synapse, in Develop tab

![image.png](.attachments/image-d616064f-1469-47bc-a0d9-c2a02e3c09fe.png)

## Agenda

1. [Presentation](01.presentation.md) :clock12: **(00:00)**
2. [Introduction](02.introduction.md)
3. [Azure and microsoft resources](03.azure-microsoft-resources.md) :clock1230: **(00:30)**
4. **[Azure Synapse](04.azure-synapse.md) :clock1: (01:00)**
5. [Q&A](08.q&a.md) :clock2: **(02:00)**